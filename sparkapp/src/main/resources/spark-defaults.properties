# MinIO/S3 settings
spark.hadoop.fs.s3a.endpoint=http://localhost:9000
spark.hadoop.fs.s3a.access.key=AAAAAAAAAAAAAAAAAAAA
spark.hadoop.fs.s3a.secret.key=BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
spark.hadoop.fs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.connection.ssl.enabled=false
spark.hadoop.fs.s3a.fast.upload=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem

# Delta Lake settings
spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog

# Other settings
spark.sql.files.ignoreMissingFiles=true

# Application specific settings
spark.app.s3.base.path=s3a://datalake
spark.app.s3.table.path=s3a://datalake/dummy/table

# Cassandra settings
spark.cassandra.connection.host=127.0.0.1
spark.cassandra.connection.port=9042
spark.cassandra.auth.username=admin
spark.cassandra.auth.password=admin
spark.sql.extensions=com.datastax.spark.connector.CassandraSparkExtensions

spark.app.cassandra.keyspace=default
spark.app.cassandra.table=network

# Postgres settings
spark.app.postgres.url=jdbc:postgresql://localhost:5432/postgres
spark.app.postgres.user=postgres
spark.app.postgres.password=postgres
spark.app.postgres.table=network